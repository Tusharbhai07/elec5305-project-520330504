# â­ **docs/index.md (Homepage)**

````markdown
---
title: ELEC5305 UrbanSound8K Automobile Sound Recognition
---

# ğŸ”Š ELEC5305 â€” Automobile Sound Recognition  
### **Hybrid CNNâ€“BiLSTM Model with Auxiliary Features**  
**Author:** Tushar Manish Khupte (SID: 520330504)  
**Unit:** ELEC5305 â€“ Audio Processing & DSP (The University of Sydney)

[![Open In Colab](https://img.shields.io/badge/Open%20In%20Colab-Deep%20Learning%20Notebook-orange?logo=googlecolab)](https://colab.research.google.com/drive/1tQ3kxnaScF5GZLx7VYJQ2cxjm3pbHZN9?usp=sharing)

---

## ğŸ“˜ Overview

This project implements a **reproducible, end-to-end UrbanSound8K classification pipeline** focused on *automobile-related sounds* (car horn, engine idling, siren).  
The final model uses:

âœ” Log-mel spectrograms  
âœ” Modulation spectrum summary  
âœ” LPC coefficients  
âœ” **CNN â†’ BiLSTM** architecture  
âœ” Early stopping using **macro-F1**  
âœ” Example-matched audio (input, denoised, mel-reconstructed)

All training artifacts are auto-exported as figures, CSV logs, WAVs, and model checkpoints.

---

# ğŸ§ Key Outputs  
Below are the major results from your repository.

---

## ğŸ“Š **Confusion Matrix**

<img src="../content/outputs/confusion_matrix.png" width="600"/>

---

## ğŸ“ˆ Training Curves

### **Accuracy**
<img src="../content/outputs/plot_accuracy.png" width="600"/>

### **Loss**
<img src="../content/outputs/plot_loss.png" width="600"/>

### **Macro-F1**
<img src="../content/outputs/plot_macro_f1.png" width="600"/>

### **Per-Class F1**
<img src="../content/outputs/plot_per_class_f1.png" width="600"/>

---

# ğŸ”‰ Example Audio (Hear the Model!)

### ğŸ”Š Raw Input Audio  
Browse:  
`/content/outputs/examples/some_examples_raw_Audio_INPUT/`

### ğŸ”‰ Denoised Output  
Browse:  
`/content/outputs/examples/some_examples_denoised_audio_OUTPUT/`

### ğŸ§ Mel-Reconstruction (What the model â€œhearsâ€)  
Browse:  
`/content/outputs/examples/some_examples_Feature-Space_Reconstruction/`

### ğŸ¼ Matched Audio Pairs (Input â†’ Denoised â†’ Mel-Recon)
Browse:  
`/content/outputs/examples/audio_pairs/`

---

# ğŸ§  Model Summary

* **Baseline:** TinyCNNWithAux  
* **Proposed:** CNN + BiLSTM + Auxiliary Features  
* **Training folds:** 1â€“8  
* **Validation:** 9  
* **Testing:** 10  

**Best checkpoint:** `content/outputs/best.pt`  
**Metrics report:** `content/outputs/metrics.json`  
**Logs:** `content/outputs/training_log.csv`

---

# ğŸ“¦ Repository Structure

```text
content/
 â”œâ”€ UrbanSound8K/                
 â”œâ”€ outputs/
 â”‚   â”œâ”€ training_log.csv
 â”‚   â”œâ”€ metrics.json
 â”‚   â”œâ”€ confusion_matrix.png
 â”‚   â”œâ”€ examples/
 â”‚       â”œâ”€ test_mistakes_audio/
 â”‚       â”œâ”€ Feature-Space_Reconstruction/
 â”‚       â”œâ”€ audio_pairs/
 â”‚       â””â”€ ...
 â””â”€ us8k_cache/
Ultrasound8K_Final_Baseline(CNN-BiLSTM)_.py
````

---

# ğŸš€ How to Run

### Train:

```
python ultrasound_8k_Baseline_final_project.py
```

### Regenerate plots:

```
python ultrasound_8k_Baseline_final_project.py --plot
```

### Export audio pairs:

```
python ultrasound_8k_Baseline_final_project.py --audio 2
```

---

# ğŸ“š Academic Citation

If you cite your adapted baseline:

> *This project uses code adapted and expanded from the baseline CNN repository in [24], with a full rewritten version provided here:*
> [https://colab.research.google.com/drive/1OrVxXP27fIkz52uoJwYzG3U4Di4Y6LOY?usp=sharing](https://colab.research.google.com/drive/1OrVxXP27fIkz52uoJwYzG3U4Di4Y6LOY?usp=sharing)

---

# ğŸ™Œ Acknowledgements

* USYD ELEC5305 teaching staff
* Open-source libraries (PyTorch, Librosa, Scikit-learn)
* UrbanSound8K dataset creators


---





Just tell me!

